"""
–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ AI Recommender Service —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º
"""

import requests
import json

def test_catalog_integration():
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º –∏ LLM"""
    
    print("ü§ñ –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ AI Recommender Service")
    print("=" * 50)
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–∞
    try:
        health_response = requests.get("http://localhost:8005/health")
        if health_response.status_code == 200:
            health_data = health_response.json()
            print("‚úÖ –°–µ—Ä–≤–∏—Å –¥–æ—Å—Ç—É–ø–µ–Ω")
            print(f"   API Key configured: {health_data.get('api_key_configured', False)}")
            print(f"   API Key length: {health_data.get('api_key_length', 0)}")
        else:
            print("‚ùå –°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–∏—Å—É: {e}")
        return
    
    # 2. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    try:
        models_response = requests.get("http://localhost:8005/api/v1/models")
        if models_response.status_code == 200:
            models_data = models_response.json()
            print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {len(models_data['available_models'])}")
            for alias, full_name in models_data["available_models"].items():
                print(f"   {alias}: {full_name}")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
            return
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        return
    
    # 3. –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º –∏ LLM
    test_cases = [
        {
            "prompt": "–†–µ–∫–æ–º–µ–Ω–¥—É–π –º–Ω–µ –ª—É—á—à–∏–µ –∫–Ω–∏–≥–∏ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞",
            "model": "gemini-pro",
            "description": "–û–±—â–∏–π –∑–∞–ø—Ä–æ—Å"
        },
        {
            "prompt": "–•–æ—á—É –ø–æ—Å–ª—É—à–∞—Ç—å —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫—É, —á—Ç–æ –ø–æ—Å–æ–≤–µ—Ç—É–µ—à—å?",
            "model": "gemini-flash", 
            "description": "–ó–∞–ø—Ä–æ—Å –ø–æ –∂–∞–Ω—Ä—É"
        },
        {
            "prompt": "–ò—â—É –Ω–µ–¥–æ—Ä–æ–≥–∏–µ –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏ –¥–æ 30 —Ä—É–±–ª–µ–π",
            "model": "claude-3",
            "description": "–ó–∞–ø—Ä–æ—Å –ø–æ —Ü–µ–Ω–µ"
        }
    ]
    
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_cases)} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤:")
    print("-" * 50)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. {test_case['description']}")
        print(f"   –ú–æ–¥–µ–ª—å: {test_case['model']}")
        print(f"   –ó–∞–ø—Ä–æ—Å: {test_case['prompt']}")
        
        try:
            response = requests.post(
                "http://localhost:8005/api/v1/recommendations/generate",
                json={
                    "prompt": test_case["prompt"],
                    "model": test_case["model"]
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                print("   ‚úÖ –£—Å–ø–µ—à–Ω–æ!")
                print(f"   ü§ñ –ú–æ–¥–µ–ª—å: {result.get('model', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}")
                print(f"   üìö –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∫–Ω–∏–≥: {result.get('total_books_analyzed', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                
                recommendations = result.get('recommendations', '')
                print(f"   üí¨ –û—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤):")
                print(f"   {recommendations[:100]}...")
                
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {response.text}")
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    print(f"\nüèÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print("=" * 50)

if __name__ == "__main__":
    test_catalog_integration()

